#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆå¤šæ™ºèƒ½ä½“åŒ»ç–—ç¯å¢ƒ

é›†æˆçœŸå®MIMIC-IIIæ•°æ®çš„å¤šæ™ºèƒ½ä½“åŒ»ç–—åä½œç¯å¢ƒï¼Œ
ä½¿ç”¨çœŸå®æ‚£è€…æ¨¡å‹å’ŒåŸºäºæ•°æ®ä¼˜åŒ–çš„å¥–åŠ±å‡½æ•°
"""

import sys
import os
import numpy as np
import pandas as pd
from pathlib import Path
import json
from typing import Dict, List, Tuple, Any, Optional
import gymnasium as gym
from gymnasium import spaces
from pettingzoo import AECEnv
from pettingzoo.utils.agent_selector import agent_selector
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.communication import CommunicationProtocol, AgentRole, MessageType, Message
from utils.config_loader import config
from env.reward_optimizer import RealDataRewardOptimizer, RewardComponents

# å¯¼å…¥æ‚£è€…æ¨¡å‹
sys.path.append(str(Path(__file__).parent.parent / "data"))
from patient_models import RealPatientModelGenerator, PatientCondition

class EnhancedMultiAgentHealthcareEnv(AECEnv):
    """å¢å¼ºç‰ˆå¤šæ™ºèƒ½ä½“åŒ»ç–—ç¯å¢ƒ"""
    
    metadata = {"render_modes": ["human"], "name": "enhanced_healthcare_v1"}
    
    def __init__(self, render_mode=None, use_real_data=True):
        super().__init__()
        
        # ç¯å¢ƒé…ç½®
        self.use_real_data = use_real_data
        self.render_mode = render_mode
        
        # æ™ºèƒ½ä½“é…ç½®
        self.agents = ["doctor", "patient", "insurance"]
        self.possible_agents = self.agents[:]
        self.agent_name_mapping = dict(zip(self.agents, list(range(len(self.agents)))))
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.communication_protocol = CommunicationProtocol()
        
        # çœŸå®æ•°æ®ç»„ä»¶
        if self.use_real_data:
            self.patient_generator = RealPatientModelGenerator()
            self.reward_optimizer = RealDataRewardOptimizer()
            self.reward_weights = self.reward_optimizer.get_optimized_weights()
        else:
            self.patient_generator = None
            self.reward_optimizer = None
            self.reward_weights = self._get_default_weights()
        
        # å½“å‰çŠ¶æ€
        self.current_patient: Optional[PatientCondition] = None
        self.episode_step = 0
        self.max_steps = 50
        self.episode_history = []
        
        # æ™ºèƒ½ä½“çŠ¶æ€
        self.agent_selector = agent_selector(self.agents)
        self.agent_selection = None
        
        # è§‚å¯Ÿå’ŒåŠ¨ä½œç©ºé—´
        self._setup_spaces()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.episode_stats = {
            'treatment_effectiveness': 0.0,
            'cost_efficiency': 0.0,
            'patient_satisfaction': 0.0,
            'communication_quality': 0.0,
            'total_reward': 0.0
        }
        
        print("ğŸ¥ Enhanced multi-agent healthcare environment initialization completed")
        if self.use_real_data:
            print("   âœ… Using real MIMIC-III data")
            print("   âœ… Optimized reward function enabled")
        else:
            print("   âš ï¸  Using simulated data")
    
    def _setup_spaces(self):
        """è®¾ç½®è§‚å¯Ÿå’ŒåŠ¨ä½œç©ºé—´"""
        # è§‚å¯Ÿç©ºé—´ï¼šæ‚£è€…çŠ¶æ€ + é€šä¿¡å†å² + ç¯å¢ƒçŠ¶æ€
        if self.use_real_data:
            # åŸºäºçœŸå®æ•°æ®çš„è§‚å¯Ÿç©ºé—´
            self.observation_spaces = {
                agent: spaces.Box(
                    low=-1.0, high=10.0, shape=(85,), dtype=np.float32
                ) for agent in self.agents
            }
        else:
            # åŸå§‹è§‚å¯Ÿç©ºé—´
            self.observation_spaces = {
                agent: spaces.Box(
                    low=-1.0, high=10.0, shape=(80,), dtype=np.float32
                ) for agent in self.agents
            }
        
        # åŠ¨ä½œç©ºé—´ï¼šå¢å¼ºçš„å¤šç¦»æ•£åŠ¨ä½œ
        self.action_spaces = {
            "doctor": spaces.MultiDiscrete([
                15,  # è¯Šæ–­åŠ¨ä½œ (æ‰©å±•)
                20,  # æ²»ç–—åŠ¨ä½œ (æ‰©å±•)
                10,  # æ£€æŸ¥åŠ¨ä½œ
                15   # é€šä¿¡åŠ¨ä½œ
            ]),
            "patient": spaces.MultiDiscrete([
                10,  # ç—‡çŠ¶æŠ¥å‘Š
                8,   # åé¦ˆåŠ¨ä½œ
                5,   # é…åˆç¨‹åº¦
                10   # é€šä¿¡åŠ¨ä½œ
            ]),
            "insurance": spaces.MultiDiscrete([
                5,   # å®¡æ‰¹åŠ¨ä½œ
                8,   # è°ƒæŸ¥åŠ¨ä½œ
                6,   # è°ˆåˆ¤åŠ¨ä½œ
                12   # é€šä¿¡åŠ¨ä½œ
            ])
        }
    
    def _get_default_weights(self) -> Dict[str, float]:
        """è·å–é»˜è®¤å¥–åŠ±æƒé‡"""
        return {
            'treatment_success': 0.20,
            'treatment_efficiency': 0.10,
            'cost_optimization': 0.15,
            'patient_safety': 0.20,
            'communication_efficiency': 0.10,
            'resource_utilization': 0.10,
            'insurance_optimization': 0.05,
            'delay_penalty': 0.05,
            'error_penalty': 0.05
        }
    
    def reset(self, seed=None, options=None):
        """é‡ç½®ç¯å¢ƒ"""
        if seed is not None:
            np.random.seed(seed)
        
        # é‡ç½®æ™ºèƒ½ä½“é€‰æ‹©å™¨
        self.agent_selector.reset()
        self.agent_selection = self.agent_selector.next()
        
        # ç”Ÿæˆæ–°æ‚£è€…
        if self.use_real_data and self.patient_generator:
            self.current_patient = self.patient_generator.generate_realistic_patient(seed=seed)
        else:
            self.current_patient = self._generate_simulated_patient()
        
        # é‡ç½®ç¯å¢ƒçŠ¶æ€
        self.episode_step = 0
        self.episode_history = []
        self.communication_protocol.clear_history()
        
        # é‡ç½®æ€§èƒ½ç»Ÿè®¡
        self.episode_stats = {
            'treatment_effectiveness': 0.0,
            'cost_efficiency': 0.0,
            'patient_satisfaction': 0.0,
            'communication_quality': 0.0,
            'total_reward': 0.0
        }
        
        # ç”Ÿæˆåˆå§‹è§‚å¯Ÿ
        self.observations = {agent: self._get_obs(agent) for agent in self.agents}
        self.rewards = {agent: 0 for agent in self.agents}
        self.terminations = {agent: False for agent in self.agents}
        self.truncations = {agent: False for agent in self.agents}
        self.infos = {agent: {} for agent in self.agents}
        
        return self.observations, self.infos
    
    def step(self, action):
        """æ‰§è¡Œä¸€æ­¥"""
        if self.terminations[self.agent_selection] or self.truncations[self.agent_selection]:
            self._was_dead_step(action)
            return
        
        agent = self.agent_selection
        
        # å¤„ç†åŠ¨ä½œ
        reward = self._process_action(agent, action)
        
        # æ›´æ–°ç¯å¢ƒçŠ¶æ€
        self.episode_step += 1
        
        # è®¡ç®—å¥–åŠ±
        self.rewards[agent] = reward
        
        # æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
        if self.episode_step >= self.max_steps:
            self.truncations = {agent: True for agent in self.agents}
        
        # æ£€æŸ¥æ²»ç–—å®Œæˆæ¡ä»¶
        if self.use_real_data and self.current_patient:
            if self._is_treatment_complete():
                self.terminations = {agent: True for agent in self.agents}
        
        # æ›´æ–°è§‚å¯Ÿ
        self.observations[agent] = self._get_obs(agent)
        
        # é€‰æ‹©ä¸‹ä¸€ä¸ªæ™ºèƒ½ä½“
        self.agent_selection = self.agent_selector.next()
        
        # ç´¯ç§¯æ€§èƒ½ç»Ÿè®¡
        self._update_episode_stats(agent, reward)
    
    def _generate_simulated_patient(self) -> PatientCondition:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ‚£è€…ï¼ˆfallbackï¼‰"""
        from dataclasses import dataclass
        
        # åˆ›å»ºåŸºæœ¬çš„æ¨¡æ‹Ÿæ‚£è€…
        patient = PatientCondition(
            subject_id=np.random.randint(1000, 9999),
            age=np.random.randint(18, 90),
            gender=np.random.randint(0, 2),
            primary_diagnosis="simulated_diagnosis",
            diagnosis_codes=["sim_001"],
            severity_score=np.random.uniform(1.0, 5.0),
            mortality_risk=np.random.uniform(0.0, 0.5),
            treatment_complexity=np.random.uniform(1.0, 3.0),
            symptoms={
                'pain': np.random.uniform(0.0, 1.0),
                'fatigue': np.random.uniform(0.0, 1.0),
                'nausea': np.random.uniform(0.0, 1.0)
            },
            current_treatments=[],
            treatment_effectiveness=0.7,
            estimated_treatment_cost=np.random.uniform(5000, 20000),
            insurance_coverage=np.random.uniform(0.6, 0.9),
            length_of_stay_prediction=np.random.uniform(3, 15),
            urgency_level=np.random.randint(1, 6)
        )
        
        return patient
    
    def _get_obs(self, agent: str) -> np.ndarray:
        """è·å–æ™ºèƒ½ä½“è§‚å¯Ÿ"""
        if not self.current_patient:
            return np.zeros(self.observation_spaces[agent].shape[0])
        
        # åŸºç¡€æ‚£è€…ä¿¡æ¯
        patient_obs = [
            self.current_patient.age / 100.0,  # æ ‡å‡†åŒ–å¹´é¾„
            float(self.current_patient.gender),
            self.current_patient.severity_score / 5.0,  # æ ‡å‡†åŒ–ä¸¥é‡ç¨‹åº¦
            self.current_patient.mortality_risk,
            self.current_patient.treatment_complexity / 5.0,
            self.current_patient.treatment_effectiveness,
            self.current_patient.estimated_treatment_cost / 50000.0,  # æ ‡å‡†åŒ–æˆæœ¬
            self.current_patient.insurance_coverage,
            self.current_patient.length_of_stay_prediction / 30.0,  # æ ‡å‡†åŒ–ä½é™¢æ—¶é•¿
            float(self.current_patient.urgency_level) / 5.0
        ]
        
        # ç—‡çŠ¶ä¿¡æ¯ï¼ˆæ‰©å±•åˆ°10ç»´ï¼‰
        symptoms = list(self.current_patient.symptoms.values())[:10]
        while len(symptoms) < 10:
            symptoms.append(0.0)
        patient_obs.extend(symptoms)
        
        # æ²»ç–—ä¿¡æ¯ï¼ˆæ‰©å±•åˆ°15ç»´ï¼‰
        treatments = [1.0 if t else 0.0 for t in self.current_patient.current_treatments[:15]]
        while len(treatments) < 15:
            treatments.append(0.0)
        patient_obs.extend(treatments)
        
        # ç¯å¢ƒçŠ¶æ€
        env_obs = [
            self.episode_step / self.max_steps,  # è¿›åº¦
            len(self.episode_history) / 100.0,  # å†å²é•¿åº¦
            self.episode_stats['treatment_effectiveness'],
            self.episode_stats['cost_efficiency'],
            self.episode_stats['patient_satisfaction']
        ]
        patient_obs.extend(env_obs)
        
        # é€šä¿¡å†å²ï¼ˆæ‰©å±•ï¼‰
        comm_obs = self._get_communication_obs(agent)
        patient_obs.extend(comm_obs)
        
        # æ™ºèƒ½ä½“ç‰¹å®šè§‚å¯Ÿ
        agent_specific_obs = self._get_agent_specific_obs(agent)
        patient_obs.extend(agent_specific_obs)
        
        # ç¡®ä¿è§‚å¯Ÿé•¿åº¦æ­£ç¡®
        obs_array = np.array(patient_obs, dtype=np.float32)
        target_length = self.observation_spaces[agent].shape[0]
        
        if len(obs_array) < target_length:
            # å¡«å……é›¶
            padding = np.zeros(target_length - len(obs_array))
            obs_array = np.concatenate([obs_array, padding])
        elif len(obs_array) > target_length:
            # æˆªæ–­
            obs_array = obs_array[:target_length]
        
        return obs_array
    
    def _get_communication_obs(self, agent: str) -> List[float]:
        """è·å–é€šä¿¡è§‚å¯Ÿ"""
        comm_obs = []
        
        # æœ€è¿‘çš„é€šä¿¡æ¶ˆæ¯ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        recent_messages = self.communication_protocol.get_recent_messages(count=10)
        
        for i in range(10):  # å›ºå®š10æ¡æ¶ˆæ¯
            if i < len(recent_messages):
                msg = recent_messages[i]
                comm_obs.extend([
                    float(msg.sender.value),
                    float(msg.receiver.value),
                    float(msg.message_type.value),
                    msg.priority.value / 4.0,  # æ ‡å‡†åŒ–ä¼˜å…ˆçº§
                    msg.cost / 1.0  # æ ‡å‡†åŒ–æˆæœ¬
                ])
            else:
                comm_obs.extend([0.0, 0.0, 0.0, 0.0, 0.0])
        
        return comm_obs  # 50ç»´
    
    def _get_agent_specific_obs(self, agent: str) -> List[float]:
        """è·å–æ™ºèƒ½ä½“ç‰¹å®šè§‚å¯Ÿ"""
        if agent == "doctor":
            return [
                1.0,  # åŒ»ç”Ÿæ ‡è¯†
                0.0, 0.0,
                # åŒ»ç–—ä¸“ä¸šä¿¡æ¯
                0.8,  # ä¸“ä¸šæ°´å¹³
                0.9,  # è¯Šæ–­å‡†ç¡®æ€§
            ]
        elif agent == "patient":
            return [
                0.0, 1.0, 0.0,
                # æ‚£è€…çŠ¶æ€ä¿¡æ¯
                0.7,  # é…åˆåº¦
                0.6,  # æ»¡æ„åº¦
            ]
        elif agent == "insurance":
            return [
                0.0, 0.0, 1.0,
                # ä¿é™©ä¿¡æ¯
                0.8,  # å®¡æ‰¹ç‡
                0.85, # è¦†ç›–ç‡
            ]
        else:
            return [0.0, 0.0, 0.0, 0.0, 0.0]
    
    def _process_action(self, agent: str, action) -> float:
        """å¤„ç†æ™ºèƒ½ä½“åŠ¨ä½œ"""
        if not isinstance(action, (list, tuple, np.ndarray)):
            action = [action]
        
        if agent == "doctor":
            return self._process_doctor_action(action)
        elif agent == "patient":
            return self._process_patient_action(action)
        elif agent == "insurance":
            return self._process_insurance_action(action)
        
        return 0.0
    
    def _process_doctor_action(self, action) -> float:
        """å¤„ç†åŒ»ç”ŸåŠ¨ä½œ"""
        if len(action) < 4:
            action = list(action) + [0] * (4 - len(action))
        
        diagnosis_action, treatment_action, check_action, comm_action = action[:4]
        
        # è®°å½•åŠ¨ä½œ
        action_record = {
            'agent': 'doctor',
            'step': self.episode_step,
            'diagnosis': diagnosis_action,
            'treatment': treatment_action,
            'check': check_action,
            'communication': comm_action
        }
        self.episode_history.append(action_record)
        
        # è®¡ç®—å¥–åŠ±
        reward = 0.0
        
        # æ²»ç–—åŠ¨ä½œå¥–åŠ±
        if self.use_real_data and self.reward_optimizer:
            # ä½¿ç”¨çœŸå®æ•°æ®è®¡ç®—å¥–åŠ±
            treatment_data = {
                'effectiveness': self.current_patient.treatment_effectiveness,
                'appropriateness': 0.8 + (treatment_action / 20) * 0.2,  # åŸºäºåŠ¨ä½œçš„é€‚å½“æ€§
                'efficiency': 0.7 + (diagnosis_action / 15) * 0.3
            }
            
            outcome_data = {
                'actual_cost': self.current_patient.estimated_treatment_cost * (0.8 + (treatment_action / 40)),
                'baseline_cost': self.current_patient.estimated_treatment_cost,
                'symptom_improvement': 0.6 + (treatment_action / 30) * 0.4,
                'mortality_risk_reduction': self.current_patient.mortality_risk * 0.3
            }
            
            # ä½¿ç”¨ä¼˜åŒ–çš„å¥–åŠ±å‡½æ•°
            components = self.reward_optimizer.calculate_comprehensive_reward(
                patient_data=self._get_patient_data_dict(),
                treatment_data=treatment_data,
                outcome_data=outcome_data,
                process_data={'decision_time': 5, 'communication_quality': 0.8, 'resource_utilization': 0.7}
            )
            
            reward = components.total_reward(self.reward_weights)
        else:
            # ç®€åŒ–å¥–åŠ±è®¡ç®—
            reward = (diagnosis_action + treatment_action) * 0.05
        
        # é€šä¿¡å¥–åŠ±
        if comm_action > 0:
            comm_reward = self._process_communication(AgentRole.DOCTOR, comm_action)
            reward += comm_reward
        
        return reward
    
    def _process_patient_action(self, action) -> float:
        """å¤„ç†æ‚£è€…åŠ¨ä½œ"""
        if len(action) < 4:
            action = list(action) + [0] * (4 - len(action))
        
        symptom_action, feedback_action, cooperation_action, comm_action = action[:4]
        
        # è®°å½•åŠ¨ä½œ
        action_record = {
            'agent': 'patient',
            'step': self.episode_step,
            'symptom_report': symptom_action,
            'feedback': feedback_action,
            'cooperation': cooperation_action,
            'communication': comm_action
        }
        self.episode_history.append(action_record)
        
        # è®¡ç®—å¥–åŠ±
        reward = 0.0
        
        # é…åˆåº¦å¥–åŠ±
        cooperation_reward = cooperation_action * 0.1
        reward += cooperation_reward
        
        # ç—‡çŠ¶æŠ¥å‘Šå‡†ç¡®æ€§å¥–åŠ±
        symptom_accuracy = 1.0 - abs(symptom_action - 5) / 5.0  # å‡è®¾5æ˜¯æœ€å‡†ç¡®çš„æŠ¥å‘Š
        reward += symptom_accuracy * 0.2
        
        # é€šä¿¡å¥–åŠ±
        if comm_action > 0:
            comm_reward = self._process_communication(AgentRole.PATIENT, comm_action)
            reward += comm_reward
        
        return reward
    
    def _process_insurance_action(self, action) -> float:
        """å¤„ç†ä¿é™©åŠ¨ä½œ"""
        if len(action) < 4:
            action = list(action) + [0] * (4 - len(action))
        
        approval_action, investigation_action, negotiation_action, comm_action = action[:4]
        
        # è®°å½•åŠ¨ä½œ
        action_record = {
            'agent': 'insurance',
            'step': self.episode_step,
            'approval': approval_action,
            'investigation': investigation_action,
            'negotiation': negotiation_action,
            'communication': comm_action
        }
        self.episode_history.append(action_record)
        
        # è®¡ç®—å¥–åŠ±
        reward = 0.0
        
        # å®¡æ‰¹æ•ˆç‡å¥–åŠ±
        if approval_action > 0:
            # åŸºäºä¿é™©è¦†ç›–ç‡å’Œæˆæœ¬çš„å®¡æ‰¹å¥–åŠ±
            coverage_factor = self.current_patient.insurance_coverage
            cost_factor = 1.0 - (self.current_patient.estimated_treatment_cost / 50000.0)
            approval_reward = approval_action * 0.1 * coverage_factor * max(0.1, cost_factor)
            reward += approval_reward
        
        # è°ƒæŸ¥å‡†ç¡®æ€§å¥–åŠ±
        investigation_reward = investigation_action * 0.05
        reward += investigation_reward
        
        # é€šä¿¡å¥–åŠ±
        if comm_action > 0:
            comm_reward = self._process_communication(AgentRole.INSURANCE, comm_action)
            reward += comm_reward
        
        return reward
    
    def _process_communication(self, sender_role: AgentRole, comm_action: int) -> float:
        """å¤„ç†é€šä¿¡åŠ¨ä½œ"""
        # ç®€åŒ–çš„é€šä¿¡å¤„ç†
        comm_cost = 0.1
        comm_effectiveness = min(comm_action / 10.0, 1.0)
        
        return comm_effectiveness * 0.1 - comm_cost
    
    def _get_patient_data_dict(self) -> Dict:
        """è·å–æ‚£è€…æ•°æ®å­—å…¸"""
        if not self.current_patient:
            return {}
        
        return {
            'severity': self.current_patient.severity_score,
            'insurance_coverage': self.current_patient.insurance_coverage,
            'age': self.current_patient.age,
            'mortality_risk': self.current_patient.mortality_risk
        }
    
    def _is_treatment_complete(self) -> bool:
        """æ£€æŸ¥æ²»ç–—æ˜¯å¦å®Œæˆ"""
        # æ›´åˆç†çš„å®Œæˆæ¡ä»¶ - åªåœ¨æ¥è¿‘æœ€å¤§æ­¥æ•°æ—¶æ‰è€ƒè™‘å®Œæˆ
        if self.episode_step < self.max_steps * 0.8:  # è‡³å°‘å®Œæˆ80%çš„æ­¥æ•°
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å……åˆ†çš„åä½œå’Œæ²»ç–—
        doctor_actions = [h for h in self.episode_history if h['agent'] == 'doctor']
        patient_actions = [h for h in self.episode_history if h['agent'] == 'patient']
        insurance_actions = [h for h in self.episode_history if h['agent'] == 'insurance']
        
        # éœ€è¦æ¯ä¸ªæ™ºèƒ½ä½“éƒ½æœ‰è¶³å¤Ÿçš„å‚ä¸
        if (len(doctor_actions) >= 5 and 
            len(patient_actions) >= 5 and 
            len(insurance_actions) >= 5 and
            self.episode_stats['treatment_effectiveness'] > 0.7):
            return True
        
        return False
    
    def _update_episode_stats(self, agent: str, reward: float):
        """Update episode statistics"""
        self.episode_stats['total_reward'] += reward
        
        # Update specific metrics based on agent actions
        if agent == 'doctor':
            self.episode_stats['treatment_effectiveness'] = min(
                self.episode_stats['treatment_effectiveness'] + reward * 0.1, 1.0
            )
            # Doctor contributes to communication quality through medical communication
            self.episode_stats['communication_quality'] = min(
                self.episode_stats['communication_quality'] + abs(reward) * 0.08, 1.0
            )
        elif agent == 'patient':
            self.episode_stats['patient_satisfaction'] = min(
                self.episode_stats['patient_satisfaction'] + reward * 0.2, 1.0
            )
            # Patient contributes to communication quality through cooperation and feedback
            self.episode_stats['communication_quality'] = min(
                self.episode_stats['communication_quality'] + abs(reward) * 0.12, 1.0
            )
        elif agent == 'insurance':
            self.episode_stats['cost_efficiency'] = min(
                self.episode_stats['cost_efficiency'] + reward * 0.15, 1.0
            )
            # Insurance contributes to communication quality through efficient coordination
            self.episode_stats['communication_quality'] = min(
                self.episode_stats['communication_quality'] + abs(reward) * 0.10, 1.0
            )
    
    def render(self):
        """æ¸²æŸ“ç¯å¢ƒ"""
        if self.render_mode == "human":
            print(f"\n=== Episode Step {self.episode_step} ===")
            if self.current_patient:
                print(f"æ‚£è€…: {self.current_patient.age}å², ä¸¥é‡ç¨‹åº¦: {self.current_patient.severity_score:.2f}")
                print(f"å½“å‰æ™ºèƒ½ä½“: {self.agent_selection}")
            print(f"Episodeç»Ÿè®¡: {self.episode_stats}")
    
    def close(self):
        """å…³é—­ç¯å¢ƒ"""
        pass

def test_enhanced_environment():
    """æµ‹è¯•å¢å¼ºç‰ˆç¯å¢ƒ"""
    print("ğŸ§ª æµ‹è¯•å¢å¼ºç‰ˆå¤šæ™ºèƒ½ä½“åŒ»ç–—ç¯å¢ƒ")
    print("=" * 60)
    
    # åˆ›å»ºç¯å¢ƒ
    env = EnhancedMultiAgentHealthcareEnv(render_mode="human", use_real_data=True)
    
    # é‡ç½®ç¯å¢ƒ
    observations, infos = env.reset(seed=42)
    
    print(f"\nğŸ”„ ç¯å¢ƒé‡ç½®å®Œæˆ")
    print(f"æ™ºèƒ½ä½“: {env.agents}")
    print(f"å½“å‰æ‚£è€…ID: {env.current_patient.subject_id}")
    print(f"æ‚£è€…è¯Šæ–­: {env.current_patient.primary_diagnosis}")
    print(f"ä¸¥é‡ç¨‹åº¦: {env.current_patient.severity_score:.2f}")
    
    # è¿è¡Œå‡ æ­¥
    for step in range(10):
        agent = env.agent_selection
        
        # ç”ŸæˆéšæœºåŠ¨ä½œ
        if agent == "doctor":
            action = [np.random.randint(0, 15), np.random.randint(0, 20), 
                     np.random.randint(0, 10), np.random.randint(0, 15)]
        elif agent == "patient":
            action = [np.random.randint(0, 10), np.random.randint(0, 8), 
                     np.random.randint(0, 5), np.random.randint(0, 10)]
        elif agent == "insurance":
            action = [np.random.randint(0, 5), np.random.randint(0, 8), 
                     np.random.randint(0, 6), np.random.randint(0, 12)]
        
        # æ‰§è¡ŒåŠ¨ä½œ
        env.step(action)
        
        # æ¸²æŸ“
        if step % 3 == 0:
            env.render()
        
        # æ£€æŸ¥ç»ˆæ­¢
        if all(env.terminations.values()) or all(env.truncations.values()):
            break
    
    print(f"\nğŸ“Š æœ€ç»ˆEpisodeç»Ÿè®¡:")
    for key, value in env.episode_stats.items():
        print(f"   {key}: {value:.3f}")
    
    env.close()
    print("\nâœ… æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    test_enhanced_environment() 