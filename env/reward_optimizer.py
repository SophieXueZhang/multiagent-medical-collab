#!/usr/bin/env python3
"""
åŸºäºçœŸå®æ•°æ®çš„å¥–åŠ±å‡½æ•°ä¼˜åŒ–å™¨

ä½¿ç”¨MIMIC-IIIæ•°æ®ä¼˜åŒ–å¤šæ™ºèƒ½ä½“åŒ»ç–—åä½œç¯å¢ƒçš„å¥–åŠ±å‡½æ•°ï¼Œ
ç¡®ä¿å¥–åŠ±æœºåˆ¶åæ˜ çœŸå®åŒ»ç–—ç¯å¢ƒçš„ç›®æ ‡å’Œçº¦æŸ
"""

import sys
import os
import pandas as pd
import numpy as np
from pathlib import Path
import json
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.config_loader import config

@dataclass
class RewardComponents:
    """å¥–åŠ±ç»„ä»¶æ•°æ®ç±»"""
    # æ²»ç–—æ•ˆæœç›¸å…³
    treatment_success: float = 0.0
    treatment_efficiency: float = 0.0
    symptom_improvement: float = 0.0
    
    # æˆæœ¬æ•ˆç‡ç›¸å…³
    cost_optimization: float = 0.0
    resource_utilization: float = 0.0
    length_of_stay_optimization: float = 0.0
    
    # æ‚£è€…å®‰å…¨ç›¸å…³
    mortality_risk_reduction: float = 0.0
    complication_prevention: float = 0.0
    treatment_appropriateness: float = 0.0
    
    # åä½œæ•ˆç‡ç›¸å…³
    communication_efficiency: float = 0.0
    decision_speed: float = 0.0
    information_sharing: float = 0.0
    
    # ä¿é™©ç›¸å…³
    insurance_optimization: float = 0.0
    approval_efficiency: float = 0.0
    
    # æƒ©ç½šé¡¹
    delay_penalty: float = 0.0
    error_penalty: float = 0.0
    
    def total_reward(self, weights: Dict[str, float]) -> float:
        """è®¡ç®—æ€»å¥–åŠ±"""
        components = {
            # æ­£å‘å¥–åŠ±
            'treatment_success': self.treatment_success,
            'treatment_efficiency': self.treatment_efficiency,
            'symptom_improvement': self.symptom_improvement,
            'cost_optimization': self.cost_optimization,
            'resource_utilization': self.resource_utilization,
            'length_of_stay_optimization': self.length_of_stay_optimization,
            'mortality_risk_reduction': self.mortality_risk_reduction,
            'complication_prevention': self.complication_prevention,
            'treatment_appropriateness': self.treatment_appropriateness,
            'communication_efficiency': self.communication_efficiency,
            'decision_speed': self.decision_speed,
            'information_sharing': self.information_sharing,
            'insurance_optimization': self.insurance_optimization,
            'approval_efficiency': self.approval_efficiency,
            
            # è´Ÿå‘æƒ©ç½š
            'delay_penalty': -self.delay_penalty,
            'error_penalty': -self.error_penalty
        }
        
        total = sum(components[key] * weights.get(key, 0.0) for key in components)
        return total

class RealDataRewardOptimizer:
    """åŸºäºçœŸå®æ•°æ®çš„å¥–åŠ±å‡½æ•°ä¼˜åŒ–å™¨"""
    
    def __init__(self, processed_data_path="data/processed/"):
        self.data_path = Path(processed_data_path)
        
        # åŠ è½½é¢„å¤„ç†æ•°æ®
        self.patients_df = None
        self.episodes_df = None
        self.diagnoses_mapping = None
        self.drugs_mapping = None
        self.cost_mapping = None
        
        # åŸºå‡†ç»Ÿè®¡æ•°æ®
        self.benchmarks = {}
        
        # ä¼˜åŒ–çš„å¥–åŠ±æƒé‡
        self.optimized_weights = {}
        
        print("ğŸ¯ åˆå§‹åŒ–åŸºäºçœŸå®æ•°æ®çš„å¥–åŠ±å‡½æ•°ä¼˜åŒ–å™¨")
        self.load_data()
        self.calculate_benchmarks()
        self.optimize_reward_weights()
    
    def load_data(self):
        """åŠ è½½é¢„å¤„ç†æ•°æ®"""
        print("\nğŸ“¥ åŠ è½½é¢„å¤„ç†æ•°æ®...")
        
        try:
            self.patients_df = pd.read_csv(self.data_path / "patients.csv")
            self.episodes_df = pd.read_csv(self.data_path / "episodes.csv")
            self.diagnoses_mapping = pd.read_csv(self.data_path / "diagnoses_mapping.csv")
            self.drugs_mapping = pd.read_csv(self.data_path / "drugs_mapping.csv")
            self.cost_mapping = pd.read_csv(self.data_path / "cost_mapping.csv")
            
            print(f"   âœ… æ•°æ®åŠ è½½å®Œæˆ")
        except Exception as e:
            print(f"   âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise
    
    def calculate_benchmarks(self):
        """è®¡ç®—åŸºå‡†ç»Ÿè®¡æ•°æ®"""
        print("\nğŸ“Š è®¡ç®—åŸºå‡†ç»Ÿè®¡æ•°æ®...")
        
        # æ²»ç–—æˆåŠŸç‡åŸºå‡†
        self.benchmarks['avg_treatment_effectiveness'] = self.drugs_mapping['effectiveness_score'].mean()
        self.benchmarks['target_treatment_effectiveness'] = 0.85  # ç›®æ ‡85%æœ‰æ•ˆæ€§
        
        # æˆæœ¬åŸºå‡†
        self.benchmarks['avg_treatment_cost'] = self.cost_mapping['estimated_cost'].mean()
        self.benchmarks['target_cost_reduction'] = 0.15  # ç›®æ ‡å‡å°‘15%æˆæœ¬
        
        # ä½é™¢æ—¶é•¿åŸºå‡†
        self.benchmarks['avg_length_of_stay'] = self.episodes_df['length_of_stay'].mean()
        self.benchmarks['target_los_reduction'] = 0.20  # ç›®æ ‡å‡å°‘20%ä½é™¢æ—¶é•¿
        
        # æ­»äº¡ç‡åŸºå‡†
        self.benchmarks['avg_mortality_rate'] = self.episodes_df['hospital_expire_flag'].mean()
        self.benchmarks['target_mortality_reduction'] = 0.25  # ç›®æ ‡å‡å°‘25%æ­»äº¡ç‡
        
        # ä¸¥é‡ç¨‹åº¦åŸºå‡†
        self.benchmarks['avg_severity'] = self.diagnoses_mapping['severity_score'].mean()
        self.benchmarks['avg_complexity'] = self.diagnoses_mapping['treatment_complexity'].mean()
        
        # ä¿é™©è¦†ç›–åŸºå‡†
        self.benchmarks['avg_insurance_coverage'] = self.cost_mapping['insurance_coverage'].mean()
        self.benchmarks['target_insurance_optimization'] = 0.90  # ç›®æ ‡90%ä¿é™©è¦†ç›–
        
        print(f"   âœ… åŸºå‡†æ•°æ®è®¡ç®—å®Œæˆ")
        for key, value in self.benchmarks.items():
            if isinstance(value, float):
                print(f"     {key}: {value:.3f}")
    
    def optimize_reward_weights(self):
        """ä¼˜åŒ–å¥–åŠ±æƒé‡"""
        print("\nâš–ï¸ ä¼˜åŒ–å¥–åŠ±æƒé‡...")
        
        # åŸºäºçœŸå®æ•°æ®åˆ†æçš„æƒé‡ä¼˜åŒ–
        total_weight = 1.0
        
        # ä¸»è¦ç›®æ ‡æƒé‡ï¼ˆåŸºäºåŒ»ç–—è´¨é‡ä¼˜å…ˆçº§ï¼‰
        self.optimized_weights = {
            # æ²»ç–—æ•ˆæœ (40% - æœ€é‡è¦)
            'treatment_success': 0.20,
            'treatment_efficiency': 0.10,
            'symptom_improvement': 0.10,
            
            # æ‚£è€…å®‰å…¨ (25% - ç¬¬äºŒé‡è¦)
            'mortality_risk_reduction': 0.15,
            'complication_prevention': 0.05,
            'treatment_appropriateness': 0.05,
            
            # æˆæœ¬æ•ˆç‡ (20% - ç¬¬ä¸‰é‡è¦)
            'cost_optimization': 0.10,
            'resource_utilization': 0.05,
            'length_of_stay_optimization': 0.05,
            
            # åä½œæ•ˆç‡ (10% - æ”¯æŒç›®æ ‡)
            'communication_efficiency': 0.03,
            'decision_speed': 0.04,
            'information_sharing': 0.03,
            
            # ä¿é™©ä¼˜åŒ– (5% - è¿è¥æ•ˆç‡)
            'insurance_optimization': 0.03,
            'approval_efficiency': 0.02,
            
            # æƒ©ç½šæƒé‡
            'delay_penalty': 0.1,
            'error_penalty': 0.2
        }
        
        # åŸºäºæ•°æ®ç‰¹å¾è°ƒæ•´æƒé‡
        # å¦‚æœæ­»äº¡ç‡è¾ƒé«˜ï¼Œå¢åŠ å®‰å…¨ç›¸å…³æƒé‡
        if self.benchmarks['avg_mortality_rate'] > 0.25:
            self.optimized_weights['mortality_risk_reduction'] += 0.05
            self.optimized_weights['treatment_success'] -= 0.03
            self.optimized_weights['cost_optimization'] -= 0.02
        
        # å¦‚æœæˆæœ¬è¾ƒé«˜ï¼Œå¢åŠ æˆæœ¬ä¼˜åŒ–æƒé‡
        if self.benchmarks['avg_treatment_cost'] > 15000:
            self.optimized_weights['cost_optimization'] += 0.03
            self.optimized_weights['length_of_stay_optimization'] += 0.02
            self.optimized_weights['treatment_efficiency'] -= 0.05
        
        # å¦‚æœä½é™¢æ—¶é•¿è¾ƒé•¿ï¼Œå¢åŠ æ•ˆç‡æƒé‡
        if self.benchmarks['avg_length_of_stay'] > 10:
            self.optimized_weights['length_of_stay_optimization'] += 0.03
            self.optimized_weights['decision_speed'] += 0.02
            self.optimized_weights['symptom_improvement'] -= 0.05
        
        print(f"   âœ… æƒé‡ä¼˜åŒ–å®Œæˆ")
        print(f"   ğŸ“‹ ä¼˜åŒ–åçš„æƒé‡åˆ†å¸ƒ:")
        for component, weight in self.optimized_weights.items():
            if weight > 0.01:  # åªæ˜¾ç¤ºé‡è¦æƒé‡
                print(f"     {component}: {weight:.3f}")
    
    def calculate_treatment_success_reward(self, 
                                         treatment_effectiveness: float, 
                                         patient_severity: float,
                                         treatment_appropriateness: float = 1.0) -> float:
        """è®¡ç®—æ²»ç–—æˆåŠŸå¥–åŠ±"""
        # åŸºç¡€æˆåŠŸå¥–åŠ±
        base_reward = treatment_effectiveness
        
        # ä¸¥é‡ç¨‹åº¦è°ƒæ•´ï¼ˆæ²»ç–—ä¸¥é‡ç–¾ç—…ç»™æ›´é«˜å¥–åŠ±ï¼‰
        severity_bonus = patient_severity / self.benchmarks['avg_severity'] * 0.2
        
        # æ²»ç–—é€‚å½“æ€§è°ƒæ•´
        appropriateness_factor = treatment_appropriateness
        
        # ä¸åŸºå‡†æ¯”è¾ƒ
        benchmark_factor = treatment_effectiveness / self.benchmarks['avg_treatment_effectiveness']
        
        final_reward = (base_reward + severity_bonus) * appropriateness_factor * benchmark_factor
        return max(0, min(final_reward, 2.0))  # é™åˆ¶åœ¨0-2èŒƒå›´
    
    def calculate_cost_optimization_reward(self, 
                                         actual_cost: float, 
                                         baseline_cost: float,
                                         insurance_coverage: float) -> float:
        """è®¡ç®—æˆæœ¬ä¼˜åŒ–å¥–åŠ±"""
        # æˆæœ¬èŠ‚çº¦æ¯”ä¾‹
        if baseline_cost > 0:
            cost_savings_ratio = (baseline_cost - actual_cost) / baseline_cost
        else:
            cost_savings_ratio = 0
        
        # åŸºç¡€æˆæœ¬å¥–åŠ±
        base_reward = cost_savings_ratio
        
        # ä¿é™©è¦†ç›–è°ƒæ•´
        insurance_factor = insurance_coverage / self.benchmarks['avg_insurance_coverage']
        
        # ä¸ç›®æ ‡æ¯”è¾ƒ
        target_factor = cost_savings_ratio / self.benchmarks['target_cost_reduction'] if self.benchmarks['target_cost_reduction'] > 0 else 1
        
        final_reward = base_reward * insurance_factor * target_factor
        return max(-1.0, min(final_reward, 1.0))  # é™åˆ¶åœ¨-1åˆ°1èŒƒå›´
    
    def calculate_safety_reward(self, 
                               mortality_risk_reduction: float,
                               complication_risk: float = 0.0,
                               treatment_safety_score: float = 1.0) -> float:
        """è®¡ç®—æ‚£è€…å®‰å…¨å¥–åŠ±"""
        # æ­»äº¡é£é™©é™ä½å¥–åŠ±
        mortality_reward = mortality_risk_reduction * 2.0  # é«˜æƒé‡
        
        # å¹¶å‘ç—‡é£é™©æƒ©ç½š
        complication_penalty = complication_risk * 0.5
        
        # æ²»ç–—å®‰å…¨æ€§å¥–åŠ±
        safety_reward = (treatment_safety_score - 0.5) * 0.5
        
        # ä¸åŸºå‡†æ¯”è¾ƒ
        benchmark_factor = mortality_risk_reduction / (self.benchmarks['avg_mortality_rate'] + 0.01)
        
        final_reward = (mortality_reward + safety_reward - complication_penalty) * benchmark_factor
        return max(0, min(final_reward, 2.0))
    
    def calculate_efficiency_reward(self, 
                                  decision_time: float,
                                  communication_quality: float,
                                  resource_utilization: float) -> float:
        """è®¡ç®—æ•ˆç‡å¥–åŠ±"""
        # å†³ç­–é€Ÿåº¦å¥–åŠ±ï¼ˆæ—¶é—´è¶ŠçŸ­è¶Šå¥½ï¼‰
        max_decision_time = 10.0  # å‡è®¾æœ€å¤§10åˆ†é’Ÿ
        decision_reward = max(0, (max_decision_time - decision_time) / max_decision_time)
        
        # æ²Ÿé€šè´¨é‡å¥–åŠ±
        communication_reward = communication_quality
        
        # èµ„æºåˆ©ç”¨ç‡å¥–åŠ±
        utilization_reward = resource_utilization
        
        # ç»¼åˆæ•ˆç‡åˆ†æ•°
        efficiency_score = (decision_reward + communication_reward + utilization_reward) / 3
        
        return max(0, min(efficiency_score, 1.0))
    
    def calculate_length_of_stay_reward(self, 
                                      predicted_los: float, 
                                      actual_los: float,
                                      patient_severity: float) -> float:
        """è®¡ç®—ä½é™¢æ—¶é•¿ä¼˜åŒ–å¥–åŠ±"""
        # åŸºäºä¸¥é‡ç¨‹åº¦çš„é¢„æœŸä½é™¢æ—¶é•¿
        severity_factor = patient_severity / self.benchmarks['avg_severity']
        expected_los = self.benchmarks['avg_length_of_stay'] * severity_factor
        
        # å®é™…è¡¨ç°ä¸é¢„æœŸæ¯”è¾ƒ
        if expected_los > 0:
            los_ratio = (expected_los - actual_los) / expected_los
        else:
            los_ratio = 0
        
        # é¢„æµ‹å‡†ç¡®æ€§å¥–åŠ±
        prediction_accuracy = 1.0 - abs(predicted_los - actual_los) / max(predicted_los, actual_los, 1.0)
        
        # ç»¼åˆå¥–åŠ±
        final_reward = los_ratio * 0.7 + prediction_accuracy * 0.3
        
        return max(-0.5, min(final_reward, 1.0))
    
    def calculate_insurance_optimization_reward(self, 
                                              insurance_coverage: float,
                                              approval_time: float,
                                              claim_accuracy: float) -> float:
        """è®¡ç®—ä¿é™©ä¼˜åŒ–å¥–åŠ±"""
        # è¦†ç›–ç‡å¥–åŠ±
        coverage_reward = insurance_coverage / self.benchmarks['target_insurance_optimization']
        
        # å®¡æ‰¹é€Ÿåº¦å¥–åŠ±
        max_approval_time = 24.0  # 24å°æ—¶
        approval_reward = max(0, (max_approval_time - approval_time) / max_approval_time)
        
        # å‡†ç¡®æ€§å¥–åŠ±
        accuracy_reward = claim_accuracy
        
        # ç»¼åˆä¿é™©ä¼˜åŒ–åˆ†æ•°
        insurance_score = (coverage_reward + approval_reward + accuracy_reward) / 3
        
        return max(0, min(insurance_score, 1.0))
    
    def calculate_comprehensive_reward(self, 
                                     patient_data: Dict,
                                     treatment_data: Dict,
                                     outcome_data: Dict,
                                     process_data: Dict) -> RewardComponents:
        """è®¡ç®—ç»¼åˆå¥–åŠ±"""
        components = RewardComponents()
        
        # æ²»ç–—æ•ˆæœç›¸å…³
        components.treatment_success = self.calculate_treatment_success_reward(
            treatment_data.get('effectiveness', 0.7),
            patient_data.get('severity', 1.0),
            treatment_data.get('appropriateness', 1.0)
        )
        
        components.treatment_efficiency = treatment_data.get('efficiency', 0.5)
        components.symptom_improvement = outcome_data.get('symptom_improvement', 0.5)
        
        # æˆæœ¬æ•ˆç‡ç›¸å…³
        components.cost_optimization = self.calculate_cost_optimization_reward(
            outcome_data.get('actual_cost', 10000),
            outcome_data.get('baseline_cost', 10000),
            patient_data.get('insurance_coverage', 0.8)
        )
        
        components.length_of_stay_optimization = self.calculate_length_of_stay_reward(
            outcome_data.get('predicted_los', 5),
            outcome_data.get('actual_los', 5),
            patient_data.get('severity', 1.0)
        )
        
        # æ‚£è€…å®‰å…¨ç›¸å…³
        components.mortality_risk_reduction = self.calculate_safety_reward(
            outcome_data.get('mortality_risk_reduction', 0.1),
            outcome_data.get('complication_risk', 0.0),
            treatment_data.get('safety_score', 1.0)
        )
        
        # åä½œæ•ˆç‡ç›¸å…³
        efficiency = self.calculate_efficiency_reward(
            process_data.get('decision_time', 5),
            process_data.get('communication_quality', 0.8),
            process_data.get('resource_utilization', 0.7)
        )
        
        components.communication_efficiency = efficiency * 0.4
        components.decision_speed = efficiency * 0.6
        
        # ä¿é™©ç›¸å…³
        insurance_reward = self.calculate_insurance_optimization_reward(
            patient_data.get('insurance_coverage', 0.8),
            process_data.get('approval_time', 12),
            process_data.get('claim_accuracy', 0.95)
        )
        
        components.insurance_optimization = insurance_reward * 0.7
        components.approval_efficiency = insurance_reward * 0.3
        
        # æƒ©ç½šé¡¹
        components.delay_penalty = process_data.get('delays', 0) * 0.1
        components.error_penalty = process_data.get('errors', 0) * 0.2
        
        return components
    
    def get_optimized_weights(self) -> Dict[str, float]:
        """è·å–ä¼˜åŒ–åçš„æƒé‡"""
        return self.optimized_weights.copy()
    
    def save_reward_optimization(self, output_file: str = "reward_optimization.json"):
        """ä¿å­˜å¥–åŠ±ä¼˜åŒ–ç»“æœ"""
        output_path = self.data_path / output_file
        
        optimization_data = {
            'benchmarks': self.benchmarks,
            'optimized_weights': self.optimized_weights,
            'optimization_metadata': {
                'data_source': 'MIMIC-III',
                'optimization_strategy': 'data_driven_medical_priorities',
                'creation_time': pd.Timestamp.now().isoformat()
            }
        }
        
        with open(output_path, 'w') as f:
            json.dump(optimization_data, f, indent=2)
        
        print(f"ğŸ’¾ å¥–åŠ±ä¼˜åŒ–é…ç½®å·²ä¿å­˜åˆ°: {output_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨åŸºäºçœŸå®æ•°æ®çš„å¥–åŠ±å‡½æ•°ä¼˜åŒ–")
    print("=" * 60)
    
    # åˆ›å»ºå¥–åŠ±ä¼˜åŒ–å™¨
    optimizer = RealDataRewardOptimizer()
    
    # ä¿å­˜ä¼˜åŒ–ç»“æœ
    optimizer.save_reward_optimization()
    
    # æ¼”ç¤ºå¥–åŠ±è®¡ç®—
    print(f"\nğŸ¯ å¥–åŠ±å‡½æ•°æ¼”ç¤º:")
    
    # æ¨¡æ‹Ÿæ‚£è€…å’Œæ²»ç–—æ•°æ®
    sample_patient = {
        'severity': 2.5,
        'insurance_coverage': 0.85,
        'age': 65
    }
    
    sample_treatment = {
        'effectiveness': 0.88,
        'appropriateness': 0.95,
        'efficiency': 0.80,
        'safety_score': 0.92
    }
    
    sample_outcome = {
        'actual_cost': 12000,
        'baseline_cost': 15000,
        'predicted_los': 7,
        'actual_los': 6,
        'symptom_improvement': 0.85,
        'mortality_risk_reduction': 0.15,
        'complication_risk': 0.05
    }
    
    sample_process = {
        'decision_time': 3.5,
        'communication_quality': 0.90,
        'resource_utilization': 0.85,
        'approval_time': 8.0,
        'claim_accuracy': 0.98,
        'delays': 0,
        'errors': 0
    }
    
    # è®¡ç®—ç»¼åˆå¥–åŠ±
    reward_components = optimizer.calculate_comprehensive_reward(
        sample_patient, sample_treatment, sample_outcome, sample_process
    )
    
    total_reward = reward_components.total_reward(optimizer.get_optimized_weights())
    
    print(f"   æ‚£è€…ä¸¥é‡ç¨‹åº¦: {sample_patient['severity']:.2f}")
    print(f"   æ²»ç–—æœ‰æ•ˆæ€§: {sample_treatment['effectiveness']:.2%}")
    print(f"   æˆæœ¬èŠ‚çº¦: ${sample_outcome['baseline_cost'] - sample_outcome['actual_cost']}")
    print(f"   ä½é™¢æ—¶é•¿ä¼˜åŒ–: {sample_outcome['predicted_los'] - sample_outcome['actual_los']} å¤©")
    print(f"   \nğŸ† ç»¼åˆå¥–åŠ±åˆ†æ•°: {total_reward:.3f}")
    
    print(f"\nğŸ“Š ä¸»è¦å¥–åŠ±ç»„ä»¶:")
    print(f"   æ²»ç–—æˆåŠŸ: {reward_components.treatment_success:.3f}")
    print(f"   æˆæœ¬ä¼˜åŒ–: {reward_components.cost_optimization:.3f}")
    print(f"   å®‰å…¨æ”¹å–„: {reward_components.mortality_risk_reduction:.3f}")
    print(f"   æ•ˆç‡æå‡: {reward_components.communication_efficiency + reward_components.decision_speed:.3f}")
    
    print("\nğŸ‰ å¥–åŠ±å‡½æ•°ä¼˜åŒ–å®Œæˆï¼")
    print("\nğŸ”„ ä¸‹ä¸€æ­¥å»ºè®®:")
    print("   1. å°†ä¼˜åŒ–çš„å¥–åŠ±å‡½æ•°é›†æˆåˆ°å¤šæ™ºèƒ½ä½“ç¯å¢ƒ")
    print("   2. ä½¿ç”¨çœŸå®æ‚£è€…æ¨¡å‹é‡æ–°è®­ç»ƒæ™ºèƒ½ä½“")
    print("   3. éªŒè¯æ”¹è¿›åçš„ç³»ç»Ÿæ€§èƒ½")

if __name__ == "__main__":
    main() 