# Data configuration
data:
  mimic_path: "MIMIC III/"
  processed_data_path: "data/processed/"
  train_split: 0.7
  val_split: 0.15
  test_split: 0.15

# Environment configuration
environment:
  max_episode_steps: 100
  observation_dim: 50
  action_spaces:
    doctor: 20      # Number of diagnosis + treatment options
    patient: 5      # Patient feedback options
    insurance: 3    # Approve/Deny/Request more info

# Reward function weights
rewards:
  treatment_success: 10.0
  cost_efficiency: -0.1
  time_penalty: -0.05
  communication_bonus: 2.0
  patient_satisfaction: 5.0

# Single agent training configuration
single_agent:
  algorithm: "PPO"
  total_timesteps: 100000
  learning_rate: 3e-4
  batch_size: 64
  n_epochs: 10
  gamma: 0.99
  clip_range: 0.2

# Multi-agent training configuration  
multi_agent:
  algorithm: "MAPPO"
  total_timesteps: 200000
  learning_rate: 3e-4
  batch_size: 128
  buffer_size: 50000
  update_frequency: 1000

# Network architecture
network:
  hidden_layers: [256, 128, 64]
  activation: "relu"
  dropout: 0.1

# Logging configuration
logging:
  log_interval: 1000
  save_interval: 10000
  wandb_project: "healthcare-multiagent"
  tensorboard_log: "logs/"

# Evaluation configuration
evaluation:
  eval_episodes: 100
  eval_frequency: 5000
  metrics:
    - "episode_reward"
    - "treatment_accuracy"
    - "cost_per_treatment" 
    - "communication_efficiency" 